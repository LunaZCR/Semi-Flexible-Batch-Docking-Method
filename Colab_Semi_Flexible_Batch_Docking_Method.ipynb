{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Semi-Flexible Batch Docking Method**\n",
        "\n",
        "The **Semi-Flexible Batch Docking Method** is an efficient molecular docking tool developed by **the Biocatalysis and Biotransformation Laboratory at Tianjin University of Science and Technology**.  This method is specifically designed to streamline large-scale molecular docking tasks, making it user-friendly for researchers.\n",
        "\n",
        "### Key Features:\n",
        "- **Automated Workflow**: The tool automates the pre-processing of both receptors and ligands, simplifying the initial setup.\n",
        "- **Automatic Parameter Acquisition**: It automatically retrieves the necessary docking parameters, reducing the time and effort needed for manual input.\n",
        "- **Batch Processing**: The software allows for simultaneous docking of multiple compounds, enhancing productivity in molecular design, biochemical research, and drug discovery.\n",
        "\n",
        "### Benefits:\n",
        "- **Powerful Platform**: Researchers can leverage this tool for a wide range of applications in molecular design and drug development.\n",
        "- **Flexibility**: The semi-flexible approach allows for the accommodation of conformational changes in ligands, improving docking accuracy.\n",
        "\n",
        "This method provides a robust and efficient solution for those looking to conduct molecular docking studies in an accessible manner."
      ],
      "metadata": {
        "id": "To9lWH5NvFc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Contents**\n",
        "\n",
        "1. **Configure the Environment (Required)**\n",
        "\n",
        "2. **Batch Preprocessing of Receptor and Ligand Files (Required)**\n",
        "   - 2.1 Batch Preprocessing of Receptor Files\n",
        "   - 2.2 Batch Preprocessing of Ligand Files\n",
        "\n",
        "3. **Configure the Docking Parameters (Required)**\n",
        "\n",
        "\n",
        "4. **High Throughput Molecular Docking (Required)**\n",
        "\n",
        "\n",
        "5. **Receptor File Parameter Analysis (Optional)**\n",
        "\n",
        "\n",
        "6. **References**\n",
        "\n",
        "\n",
        "7. **Troubleshooting**\n",
        "\n",
        "\n",
        "8. **Contact Us**\n",
        "\n",
        "\n",
        "9. **Related Institutions**\n",
        "\n",
        "\n",
        "10. **Related Resources**"
      ],
      "metadata": {
        "id": "jvGxCuLcvKz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configure the Environment (Required)\n",
        "\n",
        "This section provides a step-by-step guide to set up the necessary environment in Google Colab for conducting molecular docking experiments.\n",
        "\n",
        "### Step-by-Step Instructions\n",
        "\n",
        "1. **Run the Environment Configuration Code**\n",
        "   - Click the **Run** button to the left of the code cell.\n",
        "   - Follow any prompts that appear.\n",
        "   - Wait for the message: **\"Environment configuration is complete; you can continue to perform subsequent operations...\"** This indicates that the setup has finished.\n",
        "\n",
        "2. **Installation Process Overview**\n",
        "   The code will automatically execute the following tasks:\n",
        "   - Install **Miniconda**\n",
        "   - Create and activate a new conda environment\n",
        "   - Install **OpenBabel** and **PyBel**\n",
        "   - Install **Python 2.7** and **AutoDockTools**\n",
        "   - Install necessary dependency packages\n",
        "   - Set environment variables and paths\n",
        "\n",
        "3. **Important Precautions**\n",
        "   - The entire installation process may take **a few minutes**. Please be patient.\n",
        "   - If you encounter any error messages, read them carefully to identify potential issues and attempt to resolve them.\n",
        "   - Ensure that all installation steps have completed successfully before proceeding with molecular docking operations.\n",
        "\n",
        "4. **Completion Confirmation**\n",
        "   When you see the message: **\"Environment configuration is complete; proceed to the next action...\"**, it indicates that your environment has been successfully configured.\n",
        "\n",
        "After running the configuration code, your Google Colab environment will be equipped with all the necessary tools and libraries to conduct molecular docking experiments."
      ],
      "metadata": {
        "id": "-Uc7C5fsvNqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # 1. Environment Configuration\n",
        "\n",
        "# @markdown This section will guide you through the steps to configure the necessary environment in Google Colab for molecular docking. Follow the instructions carefully.\n",
        "\n",
        "# @markdown ### Instructions\n",
        "\n",
        "# @markdown #### a. Run the Configuration Code\n",
        "# @markdown - **Click the Run button** on the left side of the code cell and follow any prompts.\n",
        "# @markdown - Wait until you see the message: **\"Environment configuration is complete; you can continue to perform subsequent operations...\"** before proceeding to the next step.\n",
        "\n",
        "# @markdown #### b. Important Note\n",
        "# @markdown - In Google Colab, after installing new software packages (especially those involving Python environments and dependencies), you may need to **restart the runtime environment** for the changes to take effect. Please follow the prompts to restart the environment as needed, ensuring that the new packages and configurations load properly.\n",
        "\n",
        "# Install Miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Update PATH environment variable\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/bin')\n",
        "os.environ['PATH'] = '/usr/local/bin:' + os.environ['PATH']\n",
        "\n",
        "# Create a new conda environment\n",
        "!conda create -n openbabel_env python=3.7 -y\n",
        "\n",
        "# Install OpenBabel, RDKit, and PyBel in the new environment\n",
        "!conda install -n openbabel_env -c conda-forge openbabel rdkit -y\n",
        "\n",
        "# Activate the new environment (activation will be performed automatically in subsequent commands)\n",
        "import subprocess\n",
        "subprocess.run(['conda', 'activate', 'openbabel_env'], shell=True, check=True)\n",
        "\n",
        "# Temporarily remove PYTHONPATH environment variable\n",
        "original_pythonpath = os.environ.get('PYTHONPATH', None)\n",
        "if original_pythonpath:\n",
        "    del os.environ['PYTHONPATH']\n",
        "\n",
        "# Add package path to sys.path\n",
        "sys.path.append('/usr/local/envs/openbabel_env/lib/python3.7/site-packages')\n",
        "\n",
        "# Import PyBel\n",
        "from openbabel import pybel\n",
        "\n",
        "# Restore PYTHONPATH environment variable (if it exists)\n",
        "if original_pythonpath:\n",
        "    os.environ['PYTHONPATH'] = original_pythonpath\n",
        "\n",
        "# Install additional necessary packages\n",
        "!pip install propka matplotlib\n",
        "\n",
        "# Function to check if a command is installed\n",
        "def is_installed(command):\n",
        "    try:\n",
        "        subprocess.run([command], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        return True\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "# Install Python 2.7 and AutoDockTools\n",
        "print(\"Step 1: Installing Python 2.7 and AutoDockTools...\")\n",
        "if not is_installed('python2.7'):\n",
        "    !apt-get install -y python2.7\n",
        "    !ln -s /usr/bin/python2.7 /usr/local/bin/python2\n",
        "\n",
        "if not os.path.exists('/usr/local/autodocktools/bin/pythonsh'):\n",
        "    !wget https://ccsb.scripps.edu/mgltools/download/491/tars/releases/REL1.5.7/mgltools_x86_64Linux2_1.5.7.tar.gz -O autodocktools.tar.gz\n",
        "    !mkdir -p /usr/local/autodocktools\n",
        "    !tar -xvzf autodocktools.tar.gz -C /usr/local/autodocktools --strip-components=1\n",
        "    !tar -xvzf /usr/local/autodocktools/MGLToolsPckgs.tar.gz -C /usr/local/autodocktools/\n",
        "\n",
        "# Install csh dependency\n",
        "print(\"Step 2: Checking and installing csh dependency...\")\n",
        "if not is_installed('csh'):\n",
        "    !apt-get install -y csh\n",
        "\n",
        "# Install pip2 and numpy\n",
        "print(\"Step 3: Installing additional necessary packages...\")\n",
        "if not is_installed('pip2'):\n",
        "    !wget https://bootstrap.pypa.io/pip/2.7/get-pip.py -O get-pip.py\n",
        "    !python2.7 get-pip.py\n",
        "!pip2 install numpy\n",
        "\n",
        "# Check and create pythonsh script if it doesn't exist\n",
        "print(\"Checking and creating pythonsh script...\")\n",
        "pythonsh_path = \"/usr/local/autodocktools/bin/pythonsh\"\n",
        "if not os.path.exists(pythonsh_path):\n",
        "    pythonsh_content = \"\"\"#!/bin/bash\n",
        "/usr/bin/python2.7 \"$@\"\n",
        "\"\"\"\n",
        "    with open(pythonsh_path, \"w\") as f:\n",
        "        f.write(pythonsh_content)\n",
        "    !chmod +x /usr/local/autodocktools/bin/pythonsh\n",
        "\n",
        "# Set environment variables\n",
        "print(\"Step 4: Setting environment variables...\")\n",
        "os.environ['PYTHONPATH'] = \"/usr/local/autodocktools/MGLToolsPckgs\"\n",
        "\n",
        "# Set AutoDockTools paths\n",
        "print(\"Step 5: Setting AutoDockTools paths...\")\n",
        "mgltools_path = \"/usr/local/autodocktools/bin/pythonsh\"\n",
        "prepare_receptor4_path = \"/usr/local/autodocktools/MGLToolsPckgs/AutoDockTools/Utilities24/prepare_receptor4.py\"\n",
        "prepare_ligand4_path = \"/usr/local/autodocktools/MGLToolsPckgs/AutoDockTools/Utilities24/prepare_ligand4.py\"\n",
        "\n",
        "# Check if paths exist\n",
        "if not os.path.exists(mgltools_path):\n",
        "    print(f\"Error: Path {mgltools_path} does not exist. Please check the installation of AutoDockTools.\")\n",
        "elif not os.path.exists(prepare_receptor4_path):\n",
        "    print(f\"Error: Path {prepare_receptor4_path} does not exist. Please check the installation of AutoDockTools.\")\n",
        "elif not os.path.exists(prepare_ligand4_path):\n",
        "    print(f\"Error: Path {prepare_ligand4_path} does not exist. Please check the installation of AutoDockTools.\")\n",
        "else:\n",
        "    print(\"Environment configuration is complete; you can continue to perform subsequent operations...\")\n",
        "\n",
        "\n",
        "# @markdown Once you run this code, your Google Colab environment will be fully set up for molecular docking experiments."
      ],
      "metadata": {
        "cellView": "form",
        "id": "GcE-utB8vQJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Batch Preprocessing of Receptor and Ligand Files(Required)\n",
        "## 2.1 Batch Preprocessing of Receptor Files\n",
        "\n",
        "### Instructions\n",
        "a. Please **click the Run button** on the left side of the code cell and follow any prompts.\n",
        "\n",
        "b. After **uploading your files**, the script will automatically process them.\n",
        "\n",
        "c. Once processing is completed, the script will package the processed files and provide a download link.\n",
        "\n",
        "---\n",
        "\n",
        "## 2.2 Batch Preprocessing of Ligand Files\n",
        "\n",
        "### Instructions\n",
        "a. Please **click the Run button** on the left side of the code cell and follow any prompts.\n",
        "\n",
        "b. After uploading your small molecule structure files (in SDF, XML, or PDB format), the script will automatically convert and process them.\n",
        "\n",
        "c. Once processing is completed, the script will package the processed files and provide a download link.\n",
        "\n",
        "---\n",
        "\n",
        "### Note:\n",
        "For both receptor and ligand preprocessing, ensure that your uploaded files are in the correct format to avoid errors during processing. The output files will be in the required format for subsequent docking operations."
      ],
      "metadata": {
        "id": "vf8IuA0nvWQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 2.1 Batch Preprocessing of Receptor Files (Required)\n",
        "# @markdown a. Please **click the Run button** on the left side of the code cell and follow any prompts.\n",
        "# @markdown\n",
        "# @markdown b. After **uploading your files**, the script will automatically process them.\n",
        "# @markdown\n",
        "# @markdown c. Once processing is completed, the script will package the processed files and provide a download link.\n",
        "\n",
        "def process_receptor_files():\n",
        "    print(\"Please upload receptor files (.pdb format)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"Error: No files uploaded. Please re-upload the receptor files.\")\n",
        "        return\n",
        "\n",
        "    output_directory = 'temp_receptors/'\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        receptor_path = filename\n",
        "        print(f\"Upload successful: {receptor_path}\")\n",
        "\n",
        "        # 1. Read and perform initial processing on the receptor file\n",
        "        print(f\"Processing {receptor_path}...\")\n",
        "        result = subprocess.run([mgltools_path, prepare_receptor4_path, \"-r\", receptor_path, \"-o\", output_directory + receptor_path + \"qt\", \"-A\", \"hydrogens\", \"-U\", \"nphs_lps_waters\"], capture_output=True, text=True, env=os.environ)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Error: An error occurred while processing the file {receptor_path}. Error message: {result.stderr}\")\n",
        "            continue\n",
        "        print(f\"Initial processing of {receptor_path} completed.\")\n",
        "\n",
        "        # 2. Add hydrogen atoms\n",
        "        result = subprocess.run([mgltools_path, prepare_receptor4_path, \"-r\", output_directory + receptor_path + \"qt\", \"-A\", \"hydrogens\"], capture_output=True, text=True, env=os.environ)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Error: An error occurred while adding hydrogen atoms to {output_directory + receptor_path + 'qt'}. Error message: {result.stderr}\")\n",
        "            continue\n",
        "        print(f\"Hydrogen atoms added to {receptor_path}.\")\n",
        "\n",
        "        # 3. Add charges\n",
        "        result = subprocess.run([mgltools_path, prepare_receptor4_path, \"-r\", output_directory + receptor_path + \"qt\", \"-A\", \"charges\"], capture_output=True, text=True, env=os.environ)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Error: An error occurred while adding charges to {output_directory + receptor_path + 'qt'}. Error message: {result.stderr}\")\n",
        "            continue\n",
        "        print(f\"Charges added to {receptor_path}.\")\n",
        "\n",
        "    # Package processed files\n",
        "    print(\"Packaging processed files...\")\n",
        "    !zip -r processed_receptors.zip $output_directory\n",
        "\n",
        "    # Provide download link\n",
        "    print(\"Providing download link...\")\n",
        "    files.download('processed_receptors.zip')\n",
        "\n",
        "    print(\"All receptor files processed successfully.\")\n",
        "\n",
        "process_receptor_files()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OqpJB43kvZQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 2.2 Batch Preprocessing of Ligand Files (Required)\n",
        "# @markdown a. Please **click the Run button** on the left side of the code cell and follow any prompts.\n",
        "# @markdown\n",
        "# @markdown b. After **uploading your small molecule structure files** (in SDF, XML, or PDB format), the script will automatically convert and process them.\n",
        "# @markdown\n",
        "# @markdown c. Once processing is completed, the script will package the processed files and provide a download link.\n",
        "\n",
        "def convert_to_pdb(input_file):\n",
        "    try:\n",
        "        mol = next(pybel.readfile(os.path.splitext(input_file)[1][1:], input_file))\n",
        "        pdb_file = os.path.splitext(input_file)[0] + \".pdb\"\n",
        "        mol.write(\"pdb\", pdb_file, overwrite=True)\n",
        "        return pdb_file\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An error occurred while converting the file {input_file} to PDB format: {e}\")\n",
        "        return None\n",
        "\n",
        "# Process ligand files\n",
        "def process_ligand_files():\n",
        "    print(\"Please upload small molecule structure files (SDF, XML, or PDB format)...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"Error: No files uploaded. Please re-upload the small molecule structure files.\")\n",
        "        return\n",
        "\n",
        "    output_directory = '/content/temp_ligands/'\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        input_file = os.path.join('/content', filename)\n",
        "        file_extension = os.path.splitext(input_file)[1].lower()\n",
        "\n",
        "        if file_extension in ['.sdf', '.xml']:\n",
        "            # Convert SDF or XML format small molecule structure files to PDB format\n",
        "            pdb_file = convert_to_pdb(input_file)\n",
        "            if pdb_file is None:\n",
        "                continue\n",
        "            print(f\"Conversion successful: {input_file} -> {pdb_file}\")\n",
        "            ligand_path = pdb_file\n",
        "        elif file_extension == '.pdb':\n",
        "            ligand_path = input_file\n",
        "        else:\n",
        "            print(f\"Error: Unsupported file format {file_extension}. Please upload files in SDF, XML, or PDB format.\")\n",
        "            continue\n",
        "\n",
        "        output_ligand_path = os.path.join(output_directory, os.path.basename(ligand_path).replace('.pdb', '.pdbqt'))\n",
        "        if os.path.exists(output_ligand_path):\n",
        "            print(f\"Successfully generated: {output_ligand_path}\")\n",
        "        else:\n",
        "            print(f\"Error: Output file {output_ligand_path} does not exist.\")\n",
        "\n",
        "        # Add hydrogen and charges, and output in PDBQT format\n",
        "        print(f\"Processing {ligand_path}...\")\n",
        "        result = subprocess.run([mgltools_path, prepare_ligand4_path, \"-l\", ligand_path, \"-o\", output_ligand_path], capture_output=True, text=True, env=os.environ)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Error: An error occurred while processing the file {ligand_path}. Error message: {result.stderr}\")\n",
        "            continue\n",
        "        else:\n",
        "            if os.path.exists(output_ligand_path):\n",
        "                print(f\"Generation successful: {output_ligand_path}\")\n",
        "            else:\n",
        "                print(f\"Error: Output file {output_ligand_path} does not exist.\")\n",
        "\n",
        "        # Detect rotatable bonds and roots automatically\n",
        "        try:\n",
        "            result = subprocess.run([mgltools_path, prepare_ligand4_path, \"-l\", output_ligand_path, \"-A\", \"detect\"], capture_output=True, text=True, env=os.environ)\n",
        "            if result.returncode != 0:\n",
        "                print(f\"Warning: An error occurred while detecting rotatable bonds and roots in file {output_ligand_path}. Error message: {result.stderr}\")\n",
        "            else:\n",
        "                print(f\"Automatic detection of rotatable bonds and roots for {ligand_path} completed.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: An exception occurred during the automatic detection of rotatable bonds and roots: {e}\")\n",
        "\n",
        "    # Package processed files, only include PDBQT files\n",
        "    print(\"Packaging processed files...\")\n",
        "    pdbqt_files = [f for f in os.listdir(output_directory) if f.endswith('.pdbqt')]\n",
        "    for pdbqt_file in pdbqt_files:\n",
        "        shutil.move(os.path.join(output_directory, pdbqt_file), os.path.join(output_directory, pdbqt_file))\n",
        "\n",
        "    shutil.make_archive(\"processed_ligands\", 'zip', output_directory)\n",
        "\n",
        "    # Provide download link\n",
        "    print(\"Providing download link...\")\n",
        "    files.download('processed_ligands.zip')\n",
        "\n",
        "    print(\"All ligand files processed successfully.\")\n",
        "\n",
        "# Call the function to process ligand files\n",
        "process_ligand_files()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "19neFLM6vcIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Configure the Docking Parameters (Required)\n",
        "\n",
        "This section provides a step-by-step guide to configure docking parameters in Google Colab for molecular docking experiments.\n",
        "\n",
        "### Instructions\n",
        "1. **Upload Receptor Files**:\n",
        "   - Click the **Run button** on the left side of the code cell and follow the prompts.\n",
        "   - Upload a single receptor PDBQT, PDB file, or a ZIP file containing one or more receptor PDBQT/PDB files.\n",
        "\n",
        "2. **Upload Ligand Files**:\n",
        "   - After successfully uploading the receptor files, you will be prompted to upload small molecule ligand files (in PDB or PDBQT format).\n",
        "   - Upload one or more ligand PDBQT or PDB files.\n",
        "\n",
        "3. **Visualize Receptors and Ligands**:\n",
        "   - The uploaded receptor and ligand files will be visualized in 3D for easier analysis.\n",
        "   - A docking box will be generated based on the coordinates of the receptor and ligand, aiding in the docking process.\n",
        "\n",
        "4. **Download Docking Parameters**:\n",
        "   - After processing, the script will generate and save the docking parameters and visualizations as images.\n",
        "   - The processed files will be packaged into a ZIP file, which will be available for download.\n",
        "\n",
        "### Note:\n",
        "- Ensure that your uploaded receptor and ligand files are in the correct format to avoid errors during processing.\n",
        "- The output files will include images and parameters necessary for subsequent docking operations."
      ],
      "metadata": {
        "id": "-ZMtO5yvveVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 3. Configure the Docking Parameters (Required)\n",
        "# @markdown a. Please **click the Run button** on the left side of the code cell and follow any prompts.\n",
        "# @markdown\n",
        "# @markdown b. After **uploading your files**, the script will automatically process them.\n",
        "# @markdown\n",
        "# @markdown c. Once processing is completed, the script will package the processed.\n",
        "\n",
        "# Install py3Dmol\n",
        "!python3.10 -m pip install py3Dmol\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, FileLink\n",
        "import py3Dmol\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from itertools import combinations, product\n",
        "\n",
        "# Create output widget to display interactive messages\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "# Upload receptor file button and instructions\n",
        "upload_button_protein = widgets.FileUpload(\n",
        "    description='Upload Receptor PDB, PDBQT, or ZIP File',\n",
        "    accept='.pdb,.pdbqt,.zip',\n",
        "    multiple=True  # Allow multiple file uploads\n",
        ")\n",
        "\n",
        "instructions_protein = \"\"\"\n",
        "### Upload Receptor Files\n",
        "1. Upload a single receptor PDBQT, PDB file, or a ZIP file containing one or more receptor PDBQT/PDB files.\n",
        "\"\"\"\n",
        "\n",
        "# Upload ligand file button and instructions\n",
        "upload_button_ligand = widgets.FileUpload(\n",
        "    description='Upload Ligand PDB, PDBQT Files',\n",
        "    accept='.pdb,.pdbqt',\n",
        "    multiple=True  # Allow multiple file uploads\n",
        ")\n",
        "\n",
        "instructions_ligand = \"\"\"\n",
        "### Upload Ligand Files\n",
        "1. Upload one or more ligand PDBQT, PDB files.\n",
        "\"\"\"\n",
        "\n",
        "# Display instructions and upload buttons\n",
        "display(Markdown(instructions_protein))\n",
        "display(upload_button_protein)\n",
        "display(Markdown(instructions_ligand))\n",
        "display(upload_button_ligand)\n",
        "display(output_widget)\n",
        "\n",
        "# Function to process receptor files\n",
        "extracted_files = []\n",
        "\n",
        "def process_protein_files(change):\n",
        "    output_widget.clear_output()  # Clear previous output messages\n",
        "    if not upload_button_protein.value:\n",
        "        output_widget.append_stdout(\"Please upload receptor files\\n\")\n",
        "        return  # No files uploaded\n",
        "\n",
        "    global extracted_files\n",
        "    extracted_files = []\n",
        "    for file_name, file_info in upload_button_protein.value.items():\n",
        "        with open(file_name, 'wb') as f:\n",
        "            f.write(file_info['content'])\n",
        "        output_widget.append_stdout(f\"Uploaded Receptor: {file_name}\\n\")\n",
        "\n",
        "        # Check if the uploaded file is a ZIP file\n",
        "        if file_name.endswith('.zip'):\n",
        "            output_widget.append_stdout(f\"Extracting PDB or PDBQT files from {file_name}...\\n\")\n",
        "            with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "                zip_ref.extractall()\n",
        "                extracted_files.extend([name for name in zip_ref.namelist() if name.endswith(('.pdb', '.pdbqt'))])\n",
        "        else:\n",
        "            extracted_files.append(file_name)\n",
        "\n",
        "    # Visualize receptor files\n",
        "    for pdb_file in extracted_files:\n",
        "        viewer = py3Dmol.view(width=800, height=600)\n",
        "        with open(pdb_file, 'r') as f:\n",
        "            pdb_data = f.read()\n",
        "            viewer.addModel(pdb_data, \"pdbqt\" if pdb_file.endswith('.pdbqt') else \"pdb\")\n",
        "        viewer.setStyle({'model': 0}, {\"cartoon\": {\"color\": \"spectrum\"}})  # Color the receptor model\n",
        "        viewer.zoomTo()\n",
        "        display(viewer.show())\n",
        "\n",
        "upload_button_protein.observe(process_protein_files, names='value')\n",
        "\n",
        "# Function to process ligand files\n",
        "def process_ligand_files(change):\n",
        "    if not upload_button_ligand.value:\n",
        "        output_widget.append_stdout(\"Please upload ligand files\\n\")\n",
        "        return  # No files uploaded\n",
        "\n",
        "    ligand_files = []\n",
        "    for file_name, file_info in upload_button_ligand.value.items():\n",
        "        with open(file_name, 'wb') as f:\n",
        "            f.write(file_info['content'])\n",
        "        output_widget.append_stdout(f\"Uploaded Ligand: {file_name}\\n\")\n",
        "        ligand_files.append(file_name)\n",
        "\n",
        "    # Visualize receptors, ligands, and docking box\n",
        "    receptors = [file for file in extracted_files if file.endswith(('.pdb', '.pdbqt'))]\n",
        "    ligands = ligand_files\n",
        "\n",
        "    output_params_and_images(receptors, ligands)\n",
        "    output_widget.append_stdout(\"Receptor, ligand, and docking box visualization completed.\\n\")\n",
        "\n",
        "upload_button_ligand.observe(process_ligand_files, names='value')\n",
        "\n",
        "def parse_pdb(file_path):\n",
        "    atoms = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('ATOM') or line.startswith('HETATM'):\n",
        "                atom_info = {\n",
        "                    'atom_name': line[12:16].strip(),\n",
        "                    'residue_name': line[17:20].strip(),\n",
        "                    'chain_id': line[21].strip(),\n",
        "                    'residue_seq': int(line[22:26].strip()),\n",
        "                    'x': float(line[30:38].strip()),\n",
        "                    'y': float(line[38:46].strip()),\n",
        "                    'z': float(line[46:54].strip())\n",
        "                }\n",
        "                atoms.append(atom_info)\n",
        "    return atoms\n",
        "\n",
        "def visualize_docking_single_box(receptor_file, ligand_file, output_dir):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Read receptor\n",
        "    receptor_atoms = parse_pdb(receptor_file)\n",
        "    x_receptor = [atom['x'] for atom in receptor_atoms]\n",
        "    y_receptor = [atom['y'] for atom in receptor_atoms]\n",
        "    z_receptor = [atom['z'] for atom in receptor_atoms]\n",
        "\n",
        "    # Read ligand\n",
        "    ligand_atoms = parse_pdb(ligand_file)\n",
        "    x_ligand = [atom['x'] for atom in ligand_atoms]\n",
        "    y_ligand = [atom['y'] for atom in ligand_atoms]\n",
        "    z_ligand = [atom['z'] for atom in ligand_atoms]\n",
        "\n",
        "    # Calculate docking box\n",
        "    all_x = x_receptor + x_ligand\n",
        "    all_y = y_receptor + y_ligand\n",
        "    all_z = z_receptor + z_ligand\n",
        "\n",
        "    center_x = np.mean(all_x)\n",
        "    center_y = np.mean(all_y)\n",
        "    center_z = np.mean(all_z)\n",
        "    size_x = max(all_x) - min(all_x) + 10  # Add 10 Å buffer\n",
        "    size_y = max(all_y) - min(all_y) + 10\n",
        "    size_z = max(all_z) - min(all_z) + 10\n",
        "\n",
        "    box_min_x, box_max_x = center_x - size_x / 2, center_x + size_x / 2\n",
        "    box_min_y, box_max_y = center_y - size_y / 2, center_y + size_y / 2\n",
        "    box_min_z, box_max_z = center_z - size_z / 2, center_z + size_z / 2\n",
        "\n",
        "    # Draw 3D docking box\n",
        "    r = [box_min_x, box_max_x]\n",
        "    for s, e in combinations(np.array(list(product(r, r, r))), 2):\n",
        "        if np.sum(np.abs(s-e)) == r[1]-r[0]:\n",
        "            ax.plot3D(*zip(s, e), color=\"#AC99D2\", alpha=0.6)  # Border color and opacity\n",
        "\n",
        "    # Fill the docking box\n",
        "    xx, yy = np.meshgrid([box_min_x, box_max_x], [box_min_y, box_max_y])\n",
        "    zz = np.array([[box_min_z, box_min_z], [box_min_z, box_min_z]])\n",
        "    ax.plot_surface(xx, yy, zz, color=\"#AC99D2\", alpha=0.1)\n",
        "    zz = np.array([[box_max_z, box_max_z], [box_max_z, box_max_z]])\n",
        "    ax.plot_surface(xx, yy, zz, color=\"#AC99D2\", alpha=0.1)\n",
        "    yy, zz = np.meshgrid([box_min_y, box_max_y], [box_min_z, box_max_z])\n",
        "    xx = np.array([[box_min_x, box_min_x], [box_min_x, box_min_x]])\n",
        "    ax.plot_surface(xx, yy, zz, color=\"#AC99D2\", alpha=0.1)\n",
        "    xx = np.array([[box_max_x, box_max_x], [box_max_x, box_max_x]])\n",
        "    ax.plot_surface(xx, yy, zz, color=\"#AC99D2\", alpha=0.1)\n",
        "    xx, zz = np.meshgrid([box_min_x, box_max_x], [box_min_z, box_max_z])\n",
        "    yy = np.array([[box_min_y, box_min_y], [box_min_y, box_min_y]])\n",
        "    ax.plot_surface(xx, yy, zz, color=\"#AC99D2\", alpha=0.1)\n",
        "    yy = np.array([[box_max_y, box_max_y], [box_max_y, box_max_y]])\n",
        "    ax.plot_surface(xx, yy, zz, color=\"#AC99D2\", alpha=0.1)\n",
        "\n",
        "    # Visualize receptor\n",
        "    ax.scatter(x_receptor, y_receptor, z_receptor, label=os.path.basename(receptor_file).replace('.pdb', '').replace('.pdbqt', ''), color='#8FB4DC', alpha=0.2)\n",
        "\n",
        "    # Visualize ligand\n",
        "    ax.scatter(x_ligand, y_ligand, z_ligand, label=os.path.basename(ligand_file).replace('.pdb', '').replace('.pdbqt', ''), color='#70CDBE', alpha=1.0, s=40, marker='^')  # Different color and style\n",
        "\n",
        "    ax.set_xlim([box_min_x-10, box_max_x+10])\n",
        "    ax.set_ylim([box_min_y-10, box_max_y+10])\n",
        "    ax.set_zlim([box_min_z-10, box_max_z+10])\n",
        "\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Z')\n",
        "    ax.set_title(f'{os.path.basename(receptor_file).replace(\".pdb\", \"\").replace(\".pdbqt\", \"\")}_{os.path.basename(ligand_file).replace(\".pdb\", \"\").replace(\".pdbqt\", \"\")}')\n",
        "    ax.legend()\n",
        "\n",
        "    # Enhance visual effect\n",
        "    ax.grid(True)\n",
        "    ax.view_init(elev=20., azim=-35)\n",
        "\n",
        "    # Save image\n",
        "    img_filename = os.path.join(output_dir, f'{os.path.basename(receptor_file).replace(\".pdb\", \"\").replace(\".pdbqt\", \"\")}_{os.path.basename(ligand_file).replace(\".pdb\", \"\").replace(\".pdbqt\", \"\")}.png')\n",
        "    plt.savefig(img_filename, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    return img_filename, center_x, center_y, center_z, size_x, size_y, size_z\n",
        "\n",
        "def output_params_and_images(receptors, ligands):\n",
        "    if not os.path.exists('output'):\n",
        "        os.makedirs('output')\n",
        "\n",
        "    params_files = []\n",
        "    img_files = []\n",
        "\n",
        "    for receptor in receptors:\n",
        "        for ligand in ligands:\n",
        "            # Generate and save images and parameters\n",
        "            img_filename, center_x, center_y, center_z, size_x, size_y, size_z = visualize_docking_single_box(receptor, ligand, 'output')\n",
        "\n",
        "            # Generate parameter file\n",
        "            params_filename = os.path.join('output', f'{os.path.basename(receptor).replace(\".pdb\", \"\").replace(\".pdbqt\", \"\")}_{os.path.basename(ligand).replace(\".pdb\", \"\").replace(\".pdbqt\", \"\")}.txt')\n",
        "            with open(params_filename, 'w') as f:\n",
        "                f.write(f'Receptor: {receptor}\\n')\n",
        "                f.write(f'Ligand: {ligand}\\n')\n",
        "                f.write('Docking Type: Blind Docking\\n')\n",
        "                f.write(f'center_x = {center_x:.3f}\\n')\n",
        "                f.write(f'center_y = {center_y:.3f}\\n')\n",
        "                f.write(f'center_z = {center_z:.3f}\\n')\n",
        "                f.write(f'size_x = {size_x:.3f}\\n')\n",
        "                f.write(f'size_y = {size_y:.3f}\\n')\n",
        "                f.write(f'size_z = {size_z:.3f}\\n')\n",
        "\n",
        "            params_files.append(params_filename)\n",
        "            img_files.append(img_filename)\n",
        "\n",
        "    # Compress output files\n",
        "    with zipfile.ZipFile('Docking_parameter.zip', 'w') as zipf:\n",
        "        for file in params_files + img_files:\n",
        "            zipf.write(file)\n",
        "\n",
        "    output_widget.append_stdout(\"Output files have been generated:\")\n",
        "    display(FileLink('Docking_parameter.zip'))\n",
        "\n",
        "    # Auto download\n",
        "    files.download('Docking_parameter.zip')\n",
        "\n",
        "display(output_widget)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3_fLAAKOvhLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. High Throughput Molecular Docking (Required)\n",
        "\n",
        "This section provides a step-by-step guide for conducting high throughput molecular docking experiments in Google Colab.\n",
        "\n",
        "### Instructions\n",
        "1. **Upload Receptor Files**:\n",
        "   - Click the **Run button** on the left side of the code cell and follow the prompts.\n",
        "   - Upload a receptor file in PDBQT format or a ZIP file containing one or more receptor PDBQT files.\n",
        "\n",
        "2. **Upload Ligand Files**:\n",
        "   - After successfully uploading receptor files, you will be prompted to upload ligand files in PDBQT format or a ZIP file containing one or more ligand PDBQT files.\n",
        "\n",
        "3. **Upload Docking Parameter Files**:\n",
        "   - Upload a configuration file (in TXT or ZIP format) containing the docking parameters needed for the virtual screening process.\n",
        "\n",
        "4. **Processing and Docking**:\n",
        "   - The script will automatically extract and organize the uploaded files, execute the docking procedure using AutoDock Vina, and generate output files.\n",
        "\n",
        "5. **Results Generation**:\n",
        "   - After processing, the script will compile the docking results, including affinity scores and details of interactions, into CSV files and plots.\n",
        "\n",
        "6. **Download Docking Results**:\n",
        "   - Once processing is complete, the results will be packaged into a ZIP file, ready for download.\n",
        "\n",
        "### Note:\n",
        "- Ensure all uploaded files are in the correct formats to avoid errors during processing.\n",
        "- The generated files will include docking scores, detailed interaction data, and visualizations of the docking process."
      ],
      "metadata": {
        "id": "Ytu30-hCvje5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## 4. High throughput molecular docking (Required)\n",
        "# @markdown a. Please **click the Run button** on the left side of the code cell and follow any prompts.\n",
        "# @markdown\n",
        "# @markdown b. After **uploading your files**, the script will automatically process them.\n",
        "# @markdown\n",
        "# @markdown c. Once processing is completed, the script will package the processed.\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "vina_file = 'vina_1.2.5_linux_x86_64'\n",
        "\n",
        "# Check and download AutoDock Vina\n",
        "if not os.path.exists(vina_file):\n",
        "    print(\"Downloading AutoDock Vina...\")\n",
        "    !wget https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.5/vina_1.2.5_linux_x86_64\n",
        "    print(\"Download complete, setting execution permissions...\")\n",
        "    !chmod +x {vina_file}\n",
        "else:\n",
        "    print(\"AutoDock Vina has already been downloaded, skipping the download step.\")\n",
        "\n",
        "# Clear directory function\n",
        "def clear_directory(directory):\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "    os.makedirs(directory)\n",
        "\n",
        "# Clear receptor and ligand directories\n",
        "clear_directory('receptor')\n",
        "clear_directory('ligand')\n",
        "\n",
        "# Unzip file function\n",
        "def unzip_file(zip_file, extract_to='.'):\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"已解压缩文件: {zip_file} 到 {extract_to}\")\n",
        "\n",
        "# Move files without duplication\n",
        "def move_files(from_dir, to_dir, extension):\n",
        "    for root, dirs, files in os.walk(from_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(extension):\n",
        "                from_path = os.path.join(root, file)\n",
        "                to_path = os.path.join(to_dir, file)\n",
        "                if not os.path.exists(to_path):\n",
        "                    os.rename(from_path, to_path)\n",
        "                    print(f\"Moved to {to_dir}: {to_path}\")\n",
        "                else:\n",
        "                    print(f\"The file {to_path} already exists, skipping.\")\n",
        "\n",
        "# Upload and process receptor files\n",
        "print(\"请上传受体文件（receptor.pdbqt 或 receptor.zip）：\")\n",
        "uploaded_receptor = files.upload()\n",
        "for filename in uploaded_receptor.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        unzip_file(filename)\n",
        "        move_files('.', 'receptor', '.pdbqt')\n",
        "\n",
        "# Upload and process ligand files\n",
        "print(\"Please upload the ligand file (ligand.pdbqt or ligand.zip)：\")\n",
        "uploaded_ligand = files.upload()\n",
        "for filename in uploaded_ligand.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        # Extract directly to a temporary directory\n",
        "        temp_dir = 'temp_ligand'\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        unzip_file(filename, extract_to=temp_dir)\n",
        "        move_files(temp_dir, 'ligand', '.pdbqt')\n",
        "        shutil.rmtree(temp_dir)  # Remove temporary directory after moving files\n",
        "\n",
        "# Create conf directory\n",
        "os.makedirs('conf', exist_ok=True)\n",
        "\n",
        "# Delete duplicate files\n",
        "def delete_duplicates(directory):\n",
        "    seen_files = set()\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_name = os.path.splitext(file)[0]\n",
        "            if file_name in seen_files:\n",
        "                os.remove(os.path.join(root, file))\n",
        "                print(f\"Removed duplicate file: {file}\")\n",
        "            else:\n",
        "                seen_files.add(file_name)\n",
        "\n",
        "# Upload and process parameter files\n",
        "print(\"Upload the file (conf.txt or conf.zip) that contains the interconnection parameters.\")\n",
        "uploaded_params = files.upload()\n",
        "for filename in uploaded_params.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        # Extract to a temporary directory\n",
        "        temp_dir = 'temp_conf'\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "        unzip_file(filename, extract_to=temp_dir)\n",
        "        move_files(temp_dir, 'conf', '.txt')\n",
        "        shutil.rmtree(temp_dir)  # Remove temporary directory after moving files\n",
        "    elif filename.endswith('.txt'):\n",
        "        target_path = os.path.join('conf', filename)\n",
        "        if not os.path.exists(target_path):\n",
        "            os.rename(filename, target_path)\n",
        "        else:\n",
        "            print(f\"The object file {target_path} already exists, skipping rename.\")\n",
        "\n",
        "# Delete duplicate files in conf directory\n",
        "delete_duplicates('conf')\n",
        "\n",
        "# List files\n",
        "print(\"Unzipped file list:\", os.listdir('.'))\n",
        "\n",
        "# Read files\n",
        "receptor_files = glob.glob('receptor/*.pdbqt')\n",
        "ligand_files = glob.glob('ligand/**/*.pdbqt', recursive=True)\n",
        "param_files = glob.glob('conf/**/*.txt', recursive=True)\n",
        "\n",
        "print(\"Receptor files:\", receptor_files)\n",
        "print(\"Ligand files:\", ligand_files)\n",
        "print(\"Parameter files:\", param_files)\n",
        "\n",
        "for param_file in param_files:\n",
        "    print(f\"Read parameter file: {param_file}\")\n",
        "    with open(param_file, 'r') as f:\n",
        "        print(f.read())\n",
        "\n",
        "# Read docking parameters\n",
        "def read_docking_params(param_file):\n",
        "    params = {}\n",
        "    with open(param_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if '=' in line:\n",
        "                key, value = line.split('=')\n",
        "                params[key.strip()] = float(value.strip())\n",
        "    return params\n",
        "\n",
        "num_modes = input(\"Please enter the number of interconnection modes (default 10): \")\n",
        "num_modes = int(num_modes) if num_modes.isdigit() and int(num_modes) > 0 else 10\n",
        "print(f\"Set the number of interconnection modes to: {num_modes}\")\n",
        "\n",
        "# Docking function\n",
        "def run_docking(receptor, ligand, params):\n",
        "    output_file = f\"{os.path.splitext(os.path.basename(receptor))[0]}_{os.path.splitext(os.path.basename(ligand))[0]}_docked.pdbqt\"\n",
        "    log_file = f\"{output_file}.log\"\n",
        "\n",
        "    cmd = f\"./{vina_file} --receptor \\\"{receptor}\\\" --ligand \\\"{ligand}\\\" --center_x {params['center_x']} --center_y {params['center_y']} --center_z {params['center_z']} --size_x {params['size_x']} --size_y {params['size_y']} --size_z {params['size_z']} --num_modes {num_modes} --out \\\"{output_file}\\\"\"\n",
        "\n",
        "    print(f\"Executing command: {cmd}\")\n",
        "    exit_code = os.system(f\"{cmd} > \\\"{log_file}\\\" 2>&1\")\n",
        "\n",
        "    print(f\"Command exit code: {exit_code}\")\n",
        "\n",
        "    if exit_code != 0:\n",
        "        print(f\"Interconnection failure: {cmd}\")\n",
        "        if os.path.exists(log_file):\n",
        "            with open(log_file, 'r') as log:\n",
        "                log_content = log.read()\n",
        "                print(\"Log file content:\")\n",
        "                print(log_content)\n",
        "        return\n",
        "\n",
        "    print(f\"Docking completed: {output_file}\")\n",
        "    print(f\"Log file: {log_file}\")\n",
        "\n",
        "# Docking loop\n",
        "for receptor_file in receptor_files:\n",
        "    for ligand_file in ligand_files:\n",
        "        param_file = [pf for pf in param_files if os.path.splitext(os.path.basename(pf))[0] in receptor_file]\n",
        "        if param_file:\n",
        "            docking_params = read_docking_params(param_file[0])\n",
        "            print(f\"Parameters used: {docking_params}\")\n",
        "            run_docking(receptor_file, ligand_file, docking_params)\n",
        "\n",
        "# List generated files\n",
        "for receptor_file in receptor_files:\n",
        "    for ligand_file in ligand_files:\n",
        "        output_file = f\"{os.path.splitext(os.path.basename(receptor_file))[0]}_{os.path.splitext(os.path.basename(ligand_file))[0]}_docked.pdbqt\"\n",
        "        log_file = f\"{output_file}.log\"\n",
        "        if os.path.exists(output_file):\n",
        "            print(f\"The generated docking file: {output_file}\")\n",
        "        else:\n",
        "            print(f\"No docking file found: {output_file}\")\n",
        "\n",
        "        if os.path.exists(log_file):\n",
        "            print(f\"Generated log files: {log_file}\")\n",
        "        else:\n",
        "            print(f\"No log file found: {log_file}\")\n",
        "\n",
        "# Results parsing and clustering\n",
        "def parse_results(output_files):\n",
        "    docking_results = []\n",
        "    docking_details = []\n",
        "\n",
        "    for output_file in output_files:\n",
        "        if os.path.exists(output_file):\n",
        "            with open(output_file, 'r') as f:\n",
        "                found_score = False\n",
        "                for line in f:\n",
        "                    if line.startswith('REMARK VINA RESULT'):\n",
        "                        score = float(line.split()[3])\n",
        "                        docking_results.append(score)\n",
        "                        found_score = True\n",
        "                    elif line.startswith('REMARK VINA'):\n",
        "                        details = line.split()\n",
        "                        if len(details) > 5:\n",
        "                            position = details[5:8]\n",
        "                            interaction = details[8]\n",
        "                            docking_details.append((position, interaction))\n",
        "                if not found_score:\n",
        "                    print(f\"Warning: No docking score found in {output_file}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: Output file {output_file} does not exist.\")\n",
        "\n",
        "    return docking_results, docking_details\n",
        "\n",
        "docking_output_files = [\n",
        "    f\"{os.path.splitext(os.path.basename(receptor_file))[0]}_{os.path.splitext(os.path.basename(ligand_file))[0]}_docked.pdbqt\"\n",
        "    for receptor_file in receptor_files for ligand_file in ligand_files\n",
        "]\n",
        "\n",
        "docking_scores, docking_details = parse_results(docking_output_files)\n",
        "\n",
        "if not docking_scores:\n",
        "    print(\"No docking scores were obtained. Please check the output files.\")\n",
        "else:\n",
        "    statistics = calculate_statistics(docking_scores)\n",
        "    visualize_results(docking_scores, 'docking_affinity_distribution.png')\n",
        "    cluster_analysis(docking_scores)\n",
        "\n",
        "# Safe zip write\n",
        "def safe_zip_write(zipf, filename):\n",
        "    if os.path.exists(filename):\n",
        "        zipf.write(filename)\n",
        "    else:\n",
        "        print(f\"Unpacked: Not found {filename}\")\n",
        "\n",
        "# Statistical analysis\n",
        "def calculate_statistics(scores):\n",
        "    if not scores:\n",
        "        print(\"No scores were available for statistical analysis.\")\n",
        "        return None\n",
        "\n",
        "    mean_score = np.mean(scores)\n",
        "    median_score = np.median(scores)\n",
        "    std_score = np.std(scores)\n",
        "\n",
        "    print(f\"Statistical indicators - mean values: {mean_score:.2f}, median: {median_score:.2f}, std_score: {std_score:.2f}\")\n",
        "    return mean_score, median_score, std_score\n",
        "\n",
        "# Visualization\n",
        "def visualize_results(scores, output_image):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(scores, bins=30, kde=True)\n",
        "    plt.axvline(np.mean(scores), color='r', linestyle='--', label='Mean')\n",
        "    plt.axvline(np.median(scores), color='g', linestyle='--', label='Median')\n",
        "    plt.title(\"Docking Affinity Distribution\")\n",
        "    plt.xlabel(\"Binding Affinity (kcal/mol)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(output_image, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x=scores)\n",
        "    plt.title(\"Docking Scores Boxplot\")\n",
        "    plt.xlabel(\"Docking Scores\")\n",
        "    plt.grid()\n",
        "    plt.savefig('boxplot_docking_scores.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Clustering analysis\n",
        "def cluster_analysis(scores):\n",
        "    if len(scores) < 2:\n",
        "        print(\"Cluster analysis requires at least two data points.\")\n",
        "        return\n",
        "    scores_array = np.array(scores).reshape(-1, 1)\n",
        "    kmeans = KMeans(n_clusters=2, random_state=0).fit(scores_array)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(scores_array, np.zeros_like(scores_array), c=kmeans.labels_, cmap='viridis', s=100)\n",
        "    plt.title(\"Cluster Analysis of Docking Scores\")\n",
        "    plt.xlabel(\"Docking Scores\")\n",
        "    plt.yticks([])\n",
        "    plt.grid()\n",
        "    plt.savefig('cluster_analysis.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "docking_output_files = [\n",
        "    f\"{os.path.splitext(os.path.basename(receptor_file))[0]}_{os.path.splitext(os.path.basename(ligand_file))[0]}_docked.pdbqt\"\n",
        "    for receptor_file in receptor_files for ligand_file in ligand_files\n",
        "]\n",
        "\n",
        "docking_scores, docking_details = parse_results(docking_output_files)\n",
        "statistics = calculate_statistics(docking_scores)\n",
        "\n",
        "visualize_results(docking_scores, 'docking_affinity_distribution.png')\n",
        "cluster_analysis(docking_scores)\n",
        "\n",
        "docking_details_df = pd.DataFrame(docking_details, columns=[\"Binding Position\", \"Interaction Type\"])\n",
        "docking_details_df.to_csv('docking_details.csv', index=False)\n",
        "\n",
        "results_df = pd.DataFrame(docking_scores, columns=[\"Docking Score\"])\n",
        "results_df.to_csv('docking_scores.csv', index=False)\n",
        "\n",
        "output_zip = 'docking_results.zip'\n",
        "with zipfile.ZipFile(output_zip, 'w') as zipf:\n",
        "    for receptor_file in receptor_files:\n",
        "        for ligand_file in ligand_files:\n",
        "            output_file = f\"{os.path.splitext(os.path.basename(receptor_file))[0]}_{os.path.splitext(os.path.basename(ligand_file))[0]}_docked.pdbqt\"\n",
        "            log_file = f\"{output_file}.log\"\n",
        "            safe_zip_write(zipf, output_file)\n",
        "            safe_zip_write(zipf, log_file)\n",
        "\n",
        "    safe_zip_write(zipf, 'docking_affinity_distribution.png')\n",
        "    safe_zip_write(zipf, 'cluster_analysis.png')\n",
        "    safe_zip_write(zipf, 'boxplot_docking_scores.png')\n",
        "    safe_zip_write(zipf, 'docking_scores.csv')\n",
        "    safe_zip_write(zipf, 'docking_details.csv')\n",
        "\n",
        "print(\"Docking complete! Downloading the docking results:\")\n",
        "files.download(output_zip)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qOXYysgjvl6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Receptor File Parameter Analysis (Optional)\n",
        "\n",
        "This section provides a step-by-step guide for analyzing protein receptor files in PDB format.  The main functionalities include predicting pKa values of amino acids, calculating molecular weight and residue count, generating statistical charts, and exporting the results.\n",
        "\n",
        "### Instructions\n",
        "1.  **Run the Script**:\n",
        "- Click the **Run button** on the left side of the code cell and follow the prompts to initiate the analysis.\n",
        "\n",
        "2.  **Upload Receptor Files**:\n",
        "- Upload one or more receptor files in PDB format.  The script will automatically process these files.\n",
        "\n",
        "3.  **Processing**:\n",
        "- The script will:\n",
        "- Predict the pKa values of amino acids using PROPKA.\n",
        "- Calculate the molecular weight and number of residues for each receptor.\n",
        "- Generate statistical charts and data visualizations.\n",
        "\n",
        "4.  **Download Results**:\n",
        "- After processing is complete, the script will package the processed files, visualizations, and data into a ZIP file and provide a download link.\n",
        "\n",
        "### Note:\n",
        "- Ensure that the uploaded files are in the correct PDB format to avoid errors during processing.\n",
        "- This section is **not a required step** for conducting batch molecular docking operations;  it is optional for users who wish to analyze receptor parameters in detail.\n",
        "- The output will include detailed reports, summary statistics, and visualizations of the analysis results."
      ],
      "metadata": {
        "id": "3Ix9jePLvoxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## 5. Receptor File Parameter Analysis (Optional)\n",
        "# @markdown ### Functionality Description\n",
        "# @markdown This script is used to process protein receptor files (PDB format) with the following main functionalities:\n",
        "# @markdown 1. Use PROPKA to predict the pKa values of amino acids.\n",
        "# @markdown 2. Calculate the molecular weight and number of amino acids in the protein.\n",
        "# @markdown 3. Generate statistical charts and data analysis.\n",
        "# @markdown 4. Export the processing results and charts.\n",
        "# @markdown\n",
        "# @markdown ### Usage Instructions\n",
        "# @markdown a. Please **click the run button on the left** and follow the prompts.\n",
        "# @markdown b. **Upload one or more PDB files**, which will be processed automatically.\n",
        "# @markdown c. After processing is complete, the processed files, charts, and data will be automatically packaged and a download link will be provided.\n",
        "\n",
        "!/usr/bin/python3 -m pip install propka\n",
        "\n",
        "try:\n",
        "    from propka.run import single\n",
        "    print(\"Successfully imported propka.\")\n",
        "except ImportError as e:\n",
        "    print(f\"Import failed: {e}\")\n",
        "\n",
        "from google.colab import files as colab_files\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "import io\n",
        "import zipfile\n",
        "import re\n",
        "\n",
        "# Ensure running in Google Colab environment\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Warning: This script is designed to run in the Google Colab environment. Some functions may not work properly.\")\n",
        "\n",
        "# Check and install necessary packages\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "required_packages = ['matplotlib', 'seaborn', 'tqdm', 'pandas', 'numpy', 'propka']\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} is not installed, installing...\")\n",
        "        install(package)\n",
        "        print(f\"{package} installation complete.\")\n",
        "\n",
        "def calculate_molecular_properties(file_path):\n",
        "    try:\n",
        "        mol_weight = 0\n",
        "        num_residues = 0\n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                if line.startswith('ATOM'):\n",
        "                    atom_mass = {\n",
        "                        'C': 12.01, 'N': 14.01, 'O': 16.00, 'S': 32.07,\n",
        "                        'H': 1.008, 'P': 30.97, 'F': 19.00, 'Cl': 35.45,\n",
        "                        'Br': 79.90, 'I': 126.90\n",
        "                    }\n",
        "                    atom_type = line[76:78].strip()\n",
        "                    mol_weight += atom_mass.get(atom_type, 0)\n",
        "                    if line[17:20] != 'HOH':  # Skip water molecules\n",
        "                        num_residues += 1\n",
        "        num_residues = num_residues // 10  # Assume an average of 10 atoms per amino acid\n",
        "        return mol_weight, num_residues\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating molecular properties: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "def predict_pka_states(file_path):\n",
        "    try:\n",
        "        molecule = single(file_path)\n",
        "\n",
        "        if not hasattr(molecule, 'conformations') or len(molecule.conformations) == 0:\n",
        "            return None\n",
        "\n",
        "        first_conformation = list(molecule.conformations.values())[0]\n",
        "\n",
        "        if not hasattr(first_conformation, 'groups'):\n",
        "            return None\n",
        "\n",
        "        groups = first_conformation.groups\n",
        "\n",
        "        histidine_states = []\n",
        "        all_residue_pkas = []\n",
        "\n",
        "        for group in groups:\n",
        "            if hasattr(group, 'type'):\n",
        "                if group.type == 'HIS':\n",
        "                    histidine_states.append(group.pka_value)\n",
        "                if group.type in ['ASP', 'GLU', 'HIS', 'CYS', 'LYS', 'ARG', 'TYR']:\n",
        "                    all_residue_pkas.append((group.type, group.pka_value))\n",
        "\n",
        "        if not histidine_states and not all_residue_pkas:\n",
        "            return None\n",
        "\n",
        "        # Capture PROPKA output\n",
        "        propka_output = io.StringIO()\n",
        "        sys.stdout = propka_output\n",
        "        molecule.write_pka()\n",
        "        sys.stdout = sys.__stdout__\n",
        "        propka_summary = propka_output.getvalue()\n",
        "\n",
        "        return {\n",
        "            'histidine': histidine_states,\n",
        "            'all_residues': all_residue_pkas,\n",
        "            'propka_summary': propka_summary\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error predicting pKa states: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def visualize_results(results, output_dir):\n",
        "    custom_colors = ['#a1dce9', '#d2eeef', '#96e7d3', '#dae4be', '#ecdae5',\n",
        "                     '#938cbe', '#acb2da', '#8d9fc3', '#d2cad8', '#c7cbf6']\n",
        "\n",
        "    # Define marker styles\n",
        "    marker_styles = ['o', 's', '^', 'D', 'X', 'P', '<', '>', 'H', 'v']\n",
        "\n",
        "    # Handle color count appropriately\n",
        "    num_files = len(results['histidine_states'])\n",
        "    colors = custom_colors[:num_files] if num_files <= len(custom_colors) else sns.color_palette(\"husl\", num_files)\n",
        "\n",
        "    if results['success'] == 0:\n",
        "        print(\"No files processed successfully, unable to generate visual results.\")\n",
        "        return\n",
        "\n",
        "    file_names = [re.sub(r'\\.pdb$', '', os.path.basename(f)) for f in results['file_names']]\n",
        "\n",
        "    # 1. Pie chart: Processing result statistics\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.pie([results['success'], results['failed']], labels=['Successful', 'Failed'], autopct='%1.1f%%', colors=custom_colors[:2])\n",
        "    plt.title('Processing Result Statistics')\n",
        "    plt.savefig(os.path.join(output_dir, 'processing_result_statistics.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 2. Area chart: Histidine pKa distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if results['histidine_states']:\n",
        "        for i, histidine_pkas in enumerate(results['histidine_states']):\n",
        "            label = file_names[i]\n",
        "            sns.kdeplot(histidine_pkas, fill=True, label=label, color=colors[i])  # Continue using fill\n",
        "        plt.title('Histidine pKa Distribution')\n",
        "        plt.xlabel('pKa Value')\n",
        "        plt.ylabel('Density')\n",
        "        plt.legend()\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Histidine pKa Data', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'his_pka_distribution.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 2.1 Histogram and line chart: Overall histidine pKa distribution for all PDB files\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    all_histidine_pkas = [pka for sublist in results['histidine_states'] for pka in sublist]\n",
        "    if all_histidine_pkas:\n",
        "        sns.histplot(all_histidine_pkas, bins=20, kde=True, color=custom_colors[2])  # Use custom colors\n",
        "        plt.title('Overall Histidine pKa Distribution')\n",
        "        plt.xlabel('pKa Value')\n",
        "        plt.ylabel('Frequency')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Histidine pKa Data', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'overall_his_pka_distribution.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 3. Scatter plot: Molecular weight vs number of residues\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if results['molecular_weights'] and results['num_residues']:\n",
        "        for i, (mw, nr) in enumerate(zip(results['molecular_weights'], results['num_residues'])):\n",
        "            label = file_names[i]\n",
        "            plt.scatter(nr, mw, label=label, color=colors[i], marker=marker_styles[i % len(marker_styles)], edgecolor='k')  # Use different marker styles\n",
        "        plt.title('Molecular Weight vs Number of Residues')\n",
        "        plt.xlabel('Number of Residues')\n",
        "        plt.ylabel('Molecular Weight (Da)')\n",
        "        plt.legend()\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Molecular Weight or Number of Residues Data', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'molecular_weight_vs_amino_acid_number.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 4. Heatmap: Amino acid pKa distribution - Summary analysis\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    if results['residue_pkas']:\n",
        "        pka_df = pd.DataFrame(results['residue_pkas'], columns=['residue', 'pka', 'file'])\n",
        "        pka_summary = pka_df.groupby('residue').agg(mean_pka=('pka', 'mean'), std_pka=('pka', 'std')).reset_index()\n",
        "        pka_pivot = pka_summary.pivot(index='residue', columns='mean_pka', values='std_pka')\n",
        "        sns.heatmap(pka_pivot, annot=True, fmt='.2f', cmap='YlGnBu')\n",
        "        plt.title('Amino Acid pKa Distribution (Mean vs Std)')\n",
        "        plt.xlabel('Mean pKa')\n",
        "        plt.ylabel('Residue')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Amino Acid pKa Data', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'amino_acid_pka_distribution.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 4.1 Heatmap: Overall amino acid pKa distribution analysis\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    if results['residue_pkas']:\n",
        "        pka_df = pd.DataFrame(results['residue_pkas'], columns=['residue', 'pka', 'file'])\n",
        "        pka_matrix = pka_df.pivot_table(index='file', columns='residue', values='pka', aggfunc='mean')\n",
        "        sns.heatmap(pka_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=.5)\n",
        "        plt.title('Overall Amino Acid pKa Distribution')\n",
        "        plt.xlabel('Residue')\n",
        "        plt.ylabel('File')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Amino Acid pKa Data', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'overall_amino_acid_pka_distribution.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 5. Box plot: pKa distribution for different amino acids\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if results['residue_pkas']:\n",
        "        pka_df['file'] = pka_df['file'].apply(lambda x: re.sub(r'\\.pdb$', '', os.path.basename(x)))\n",
        "        sns.boxplot(x='residue', y='pka', hue='file', data=pka_df, palette=colors)\n",
        "        plt.title('Amino Acid pKa Box Plot')\n",
        "        plt.xlabel('Amino Acid Type')\n",
        "        plt.ylabel('pKa Value')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.legend()\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Amino Acid pKa Data', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'amino_acid_pka_box_plot.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 6. Correlation heatmap\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if results['molecular_weights'] and results['num_residues'] and results['histidine_states']:\n",
        "        corr_data = pd.DataFrame({\n",
        "            'Molecular Weight': results['molecular_weights'],\n",
        "            'Number of Residues': results['num_residues'],\n",
        "            'Average His pKa': [np.mean(his_pkas) if his_pkas else np.nan for his_pkas in results['histidine_states']]\n",
        "        })\n",
        "        sns.heatmap(corr_data.corr(), annot=True, cmap='RdYlBu')\n",
        "        plt.title('Characteristic Correlation Heat Map')\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'There is not enough data to generate a correlation heat map', ha='center', va='center')\n",
        "    plt.savefig(os.path.join(output_dir, 'correlation_heatmap.png'), dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Export data\n",
        "    if results['residue_pkas']:\n",
        "        pka_df.to_csv(os.path.join(output_dir, 'residue_pkas.csv'), index=False)\n",
        "\n",
        "    if results['molecular_weights'] and results['num_residues'] and results['histidine_states']:\n",
        "        corr_data.to_csv(os.path.join(output_dir, 'correlation_data.csv'), index=False)\n",
        "\n",
        "def process_receptor_files():\n",
        "    if not IN_COLAB:\n",
        "        print(\"This function is only available in the Google Colab environment.\")\n",
        "        return\n",
        "\n",
        "    print(\"Please upload one or more receptor files (.pdb format)...\")\n",
        "    uploaded = colab_files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"Error: No files uploaded. Please re-upload the receptor files.\")\n",
        "        return\n",
        "\n",
        "    output_directory = 'receptor_analysis_results'\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    results = {\n",
        "        'success': 0,\n",
        "        'failed': 0,\n",
        "        'histidine_states': [],\n",
        "        'residue_pkas': [],\n",
        "        'molecular_weights': [],\n",
        "        'num_residues': [],\n",
        "        'file_names': [],  # Store file names\n",
        "        'file_results': {}  # New: to store individual results for each file\n",
        "    }\n",
        "\n",
        "    log_file = io.StringIO()\n",
        "\n",
        "    for filename, file_content in uploaded.items():\n",
        "        print(f\"\\nProcessing file: {filename}\", file=log_file)\n",
        "        results['file_names'].append(filename)  # Add filename to results\n",
        "\n",
        "        try:\n",
        "            # Save uploaded file content to a temporary file\n",
        "            temp_file_path = os.path.join(output_directory, filename)\n",
        "            with open(temp_file_path, 'wb') as temp_file:\n",
        "                temp_file.write(file_content)\n",
        "\n",
        "            # 1. Use PROPKA to predict histidine protonation states and other amino acid pKa values\n",
        "            pka_results = predict_pka_states(temp_file_path)\n",
        "            if pka_results is None:\n",
        "                print(f\"Warning: pKa prediction results for file {filename} are empty\", file=log_file)\n",
        "                results['failed'] += 1\n",
        "                continue\n",
        "\n",
        "            if pka_results['histidine'] or pka_results['all_residues']:\n",
        "                results['histidine_states'].append(pka_results['histidine'])\n",
        "                results['residue_pkas'].extend([(residue, pka, filename) for residue, pka in pka_results['all_residues']])\n",
        "                print(f\"Successfully predicted pKa states: {len(pka_results['histidine'])} histidines, {len(pka_results['all_residues'])} amino acids\", file=log_file)\n",
        "\n",
        "                # Save PROPKA output results\n",
        "                with open(os.path.join(output_directory, f'{filename}_propka_summary.txt'), 'w') as f:\n",
        "                    f.write(pka_results['propka_summary'])\n",
        "            else:\n",
        "                print(f\"Warning: No valid amino acids found in file {filename}\", file=log_file)\n",
        "                results['failed'] += 1\n",
        "                continue\n",
        "\n",
        "            # 2. Calculate molecular weight and number of residues\n",
        "            mol_weight, num_res = calculate_molecular_properties(temp_file_path)\n",
        "            if mol_weight is not None and num_res is not None:\n",
        "                results['molecular_weights'].append(mol_weight)\n",
        "                results['num_residues'].append(num_res)\n",
        "                print(f\"Successfully calculated molecular properties: Molecular Weight = {mol_weight:.2f}, Number of Residues = {num_res}\", file=log_file)\n",
        "            else:\n",
        "                print(f\"Warning: Molecular property calculation for file {filename} failed\", file=log_file)\n",
        "                results['failed'] += 1\n",
        "                continue\n",
        "\n",
        "            results['success'] += 1\n",
        "            print(f\"File {filename} processed successfully\", file=log_file)\n",
        "\n",
        "            # Save individual results for each file\n",
        "            results['file_results'][filename] = {\n",
        "                'histidine_states': pka_results['histidine'],\n",
        "                'residue_pkas': pka_results['all_residues'],\n",
        "                'molecular_weight': mol_weight,\n",
        "                'num_residues': num_res\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            results['failed'] += 1\n",
        "            print(f\"File {filename} processing failed: {str(e)}\", file=log_file)\n",
        "            traceback.print_exc(file=log_file)\n",
        "\n",
        "        finally:\n",
        "            # Delete temporary file\n",
        "            if os.path.exists(temp_file_path):\n",
        "                os.remove(temp_file_path)\n",
        "\n",
        "    # Save log\n",
        "    with open(os.path.join(output_directory, 'processing_log.txt'), 'w') as f:\n",
        "        f.write(log_file.getvalue())\n",
        "\n",
        "    # Visualize processing results\n",
        "    visualize_results(results, output_directory)\n",
        "\n",
        "    # Generate individual result reports for each file\n",
        "    for filename, file_result in results['file_results'].items():\n",
        "        with open(os.path.join(output_directory, f'{filename}_results.txt'), 'w') as f:\n",
        "            f.write(f\"File: {filename}\\n\")\n",
        "            f.write(f\"Molecular Weight: {file_result['molecular_weight']:.2f} Da\\n\")\n",
        "            f.write(f\"Number of Residues: {file_result['num_residues']}\\n\")\n",
        "            f.write(f\"Histidine pKa values: {', '.join(map(str, file_result['histidine_states']))}\\n\")\n",
        "            f.write(\"Residue pKa values:\\n\")\n",
        "            for residue, pka in file_result['residue_pkas']:\n",
        "                f.write(f\"  {residue}: {pka:.2f}\\n\")\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"\\nStatistics:\")\n",
        "    print(f\"Total number of proteins processed: {results['success'] + results['failed']}\")\n",
        "    print(f\"Success rate: {results['success'] / (results['success'] + results['failed']) * 100:.2f}%\")\n",
        "\n",
        "    if results['molecular_weights']:\n",
        "        print(f\"Average molecular weight: {np.mean(results['molecular_weights']):.2f} Da\")\n",
        "    else:\n",
        "        print(\"No molecular weight data\")\n",
        "\n",
        "    if results['num_residues']:\n",
        "        print(f\"Average number of residues: {np.mean(results['num_residues']):.2f}\")\n",
        "    else:\n",
        "        print(\"No number of residues data\")\n",
        "\n",
        "        if results['histidine_states']:\n",
        "        print(f\"Average histidine pKa: {np.mean([np.mean(pkas) for pkas in results['histidine_states'] if pkas]):.2f}\")\n",
        "    else:\n",
        "        print(\"No histidine pKa data\")\n",
        "\n",
        "    # Save summary results\n",
        "    with open(os.path.join(output_directory, 'summary_results.txt'), 'w') as f:\n",
        "        f.write(\"Statistics:\\n\")\n",
        "        f.write(f\"Total number of proteins processed: {results['success'] + results['failed']}\\n\")\n",
        "        f.write(f\"Success rate: {results['success'] / (results['success'] + results['failed']) * 100:.2f}%\\n\")\n",
        "        if results['molecular_weights']:\n",
        "            f.write(f\"Average molecular weight: {np.mean(results['molecular_weights']):.2f} Da\\n\")\n",
        "        if results['num_residues']:\n",
        "            f.write(f\"Average number of residues: {np.mean(results['num_residues']):.2f}\\n\")\n",
        "        if results['histidine_states']:\n",
        "            f.write(f\"Average histidine pKa: {np.mean([np.mean(pkas) for pkas in results['histidine_states'] if pkas]):.2f}\\n\")\n",
        "\n",
        "    # Zip all output files\n",
        "    with zipfile.ZipFile('receptor_analysis_results.zip', 'w') as zipf:\n",
        "        for root, dirs, files in os.walk(output_directory):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file),\n",
        "                           os.path.relpath(os.path.join(root, file),\n",
        "                                           os.path.join(output_directory, '..')))\n",
        "\n",
        "    # Provide download link\n",
        "    colab_files.download('receptor_analysis_results.zip')\n",
        "\n",
        "# Run the main function\n",
        "process_receptor_files()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W0YLI8FFvsOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "- [Receptor Protein Files - PDB Database](https://www.rcsb.org/)\n",
        "- [Receptor Protein Files - SWISSMODEL Database](https://swissmodel.expasy.org/)\n",
        "- [Ligand Molecular Files](https://pubchem.ncbi.nlm.nih.gov/)\n",
        "- [AutoDockTools Official Documentation](https://ccsb.scripps.edu/mgltools/)\n",
        "- [Python 2.7 Documentation](https://docs.python.org/2.7/)\n",
        "- [Open Babel Official Documentation](https://openbabel.org/docs/index.html)\n",
        "- [Pybel Documentation](https://openbabel.org/docs/UseTheLibrary/Python_Pybel.html)\n",
        "\n",
        "## Troubleshooting\n",
        "If you encounter issues, please ensure that all dependencies are correctly installed and that the environment variables are properly set.\n",
        "Refer to the detailed steps above to verify your setup.\n",
        "\n",
        "## Contact Us\n",
        "For any questions or further information, please contact:   \n",
        "[chunruzhou@mail.tust.edu.cn](mailto:chunruzhou@mail.tust.edu.cn)\n",
        "\n",
        "## Related Institutions\n",
        "Tianjin University of Science and Technology\n",
        "\n",
        "Biocatalysis and Biotransformation Laboratory (**BCBT**)\n",
        "\n",
        "## Related Resources\n",
        "- [GitHub Project Link](https://github.com/LunaZCR/Semi-Flexible-Batch-Docking-Methodg)"
      ],
      "metadata": {
        "id": "5dFue-Hmvu4g"
      }
    }
  ]
}